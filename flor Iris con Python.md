## Flor Iris con Python. ( Creando un clasificador para la flor Iris con Python)



Este proyecto es uno de los b√°sicos,  que se utilizan al momento de estar aprendiendo Machine Learning.



La idea principal es construir un modelo que pueda predecir a qu√© tipo de flor pertenece una muestra, bas√°ndose en caracter√≠sticas como el tama√±o de sus p√©talos y s√©palos, para ello vamos a construir un clasificador para el Dataset de  las flores tipo Iris. 

En resumen , el dataset Iris es un problema de clasificaci√≥n supervisada, donde usamos los 4 atributos (features/entradas) para predecir la clase de flor (Species/salida)

### El dataset de Iris: 

El conjunto de datos contiene 50 muestras de cada una de tres especies de Iris (Iris setosa, Iris virginica e Iris versicolor). 

Se midi√≥ cuatro rasgos de cada muestra: el largo y ancho del s√©palo y p√©talo, en cent√≠metros:
```
1 - Caracter√≠sticas de entrada (features)
      
            Largo del s√©palo (sepal length) en cm.

            Ancho del s√©palo (sepal width) en cm. 

            Largo del p√©talo (petal length) en cm.

            Ancho del p√©talo (petal width) en cm.

2 - Etiqueta o clase (target):

                Iris setosa

                Iris versicolor

                Iris virginica
```

![image](https://github.com/user-attachments/assets/dda17548-1d7e-4826-8a1d-0a1e236694aa)
![image](https://github.com/user-attachments/assets/edd3a51a-4ac5-45a0-b9d8-7bd37e9a66d3)
![image](https://github.com/user-attachments/assets/b697eab7-2dbf-4e61-8ce5-47bfa936575a)



## Codigo python


### 1 - Importacion de Librerias

```py
# importamos librerias para nuestro proyecto.
# librerias numpy y pandas: Manejo y an√°lisis de datos num√©ricos y estructurados.

import numpy as np
import pandas as pd

# librerias para creacion y  visualizaci√≥n gr√°fica de datos.

import matplotlib.pyplot as plt
import seaborn as sns
```

```py
# Libreria sklearn: Implementa algoritmos de Machine Learning y evaluaci√≥n
import sklearn

from sklearn.model_selection import train_test_split         # Divide un conjunto de datos en dos partes: datosentrenamiento y datos de prueba.

from sklearn.ensemble import RandomForestClassifier          # Implementa un modelo de bosque aleatorio.
from sklearn.tree import DecisionTreeClassifier              # Construye un √°rbol de decisiones.
from sklearn.neighbors import KNeighborsClassifier           # Clasifica un dato bas√°ndose en los vecinos m√°s cercanos.
from sklearn.linear_model import LogisticRegression          # modelo de clasificaci√≥n 
from sklearn.svm import SVC                                  # Implementa M√°quinas de Vectores de Soporte (Support Vector Machines). 

# Importar las m√©tricas necesarias
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
```


### 2 - Carga y Lectura de Datos
```py
# leemos el archivo CSV, llamado Iris.csv y lo cargamos o en un DataFrame de pandas llamado iris.

iris = pd.read_csv("Iris.csv")
```


### 3 - Entender los datos del Dataset

```py
# Devuelve una tupla (n_filas, n_columnas): Muestra el tama√±o del DataFrame
# salida: (150, 6)

iris.shape
```




```py
# Obtener el n√∫mero total de elementos del dataframe
# es el producto del n√∫mero de filas y columnas ==> 150x6 = 900

iris.size 
```


```py
# El m√©todo .head() en pandas devuelve las primeras filas de un DataFrame, lo que te permite echar un vistazo r√°pido al contenido de los datos.
# Por defecto, muestra las primeras 5 filas

iris.head()
```

Salida:

![image](https://github.com/user-attachments/assets/058d5712-eb55-4628-995c-b472a13403ab)




```py
# Resumen general de la estructura del dataset (nombres de columnas, tipos de datos, valores nulos, etc.).

iris.info()
```

![image](https://github.com/user-attachments/assets/338eb873-b269-436c-8aed-daf231616596)

```py
Como podemos observar, todas las columnas contienen 150 datos, en las primeras tenemos datos flotantes mientras que la √∫ltima contiene datos objetos y es justamente ac√° en donde se encuentra la informaci√≥n de las especies de la flor.
```
```py
# verificamos la distribuci√≥n de los datos de acuerdo a las especies de Iris.
# Cuenta la cantidad de registros por especie (Species).

print('Distribuci√≥n de las especies de Iris:')
print(iris.groupby('Species').size())

```
![image](https://github.com/user-attachments/assets/db617603-5e74-4ba6-9ee1-2f15e150867f)

```txt
Como podemos observar tenemos 50 datos/muestras para cada una de las especies() Iris setosa, Iris versicolor e Iris Virginica).
```

```py
#Revisar si hay valores nulos
print("\nValores nulos por columna:")
print(iris.isnull().sum())
```
![image](https://github.com/user-attachments/assets/92f10e6e-b289-4605-bc6d-eb8eeb259188)

```py
# Estad√≠sticas b√°sicas de las columnas num√©ricas (media, desviaci√≥n est√°ndar, etc.).

iris.describe()
```
![image](https://github.com/user-attachments/assets/e877ffed-e837-4555-8ae3-df4682d85859)


### 4 - Transforaciones
```py
# Eliminar la columna 'Id' que no es irrelevante para el an√°lisis , se elimina para evitar que afecte los resultados.
iris = iris.drop(columns=['Id'])

iris.head()
```

![image](https://github.com/user-attachments/assets/0003edb2-281d-4967-b54c-a27be53dd063)


### 5 - Visualizaci√≥n de los datos

Ahora, vamos a representar gr√°ficamente la informaci√≥n para que sea m√°s f√°cil de entender y analizar. 
Asi, de esta forma, nos pueda permitir  identificar patrones, tendencias y anomal√≠as en los datos de manera m√°s intuitiva que simplemente observando tablas o n√∫meros.

```py
# Gr√°ficos de barras: Comparan categor√≠as.
# Vemos las cantidades de cada tipo de flor


# Configurar el tama√±o de la figura
plt.figure(figsize=(8, 6))

# Gr√°fico de conteo de especies sin advertencia
sns.countplot(x="Species", data=iris, hue="Species", palette="viridis", legend=False)

# Etiquetas y t√≠tulo
plt.title("Distribuci√≥n de Especies en el Dataset Iris")
plt.xlabel("Especie de Flor")
plt.ylabel("Cantidad")

# Mostrar el gr√°fico
plt.show()
```
![image](https://github.com/user-attachments/assets/bc534685-eec8-4fc2-a8e6-4fc70ae68b02)


```py
# Diagramas de dispersi√≥n: Analizan relaciones entre dos variables

Comparamos el ancho del s√©palo y del p√©talo de cada flor, para comprobar si existe relaci√≥n.

El siguiente c√≥digo crea dos gr√°ficos de dispersi√≥n apilados:

    1Ô∏è‚É£ El primero muestra la relaci√≥n entre el ancho (PetalWidthCm) y largo del p√©talo (PetalLengthCm) por especie.

    2Ô∏è‚É£ El segundo muestra la relaci√≥n entre el ancho (SepalWidthCm) y largo del s√©palo (SepalLengthCm) por especie.  
```



```py
# Crear la figura y los ejes
f, ax = plt.subplots(2,  # N√∫mero de filas
                     sharex=False,  # No compartir eje X
                     gridspec_kw={"height_ratios": (1, 1)},  # Proporci√≥n igual para los gr√°ficos
                     figsize=(10, 15))  # Tama√±o de la figura

# Primer gr√°fico: Relaci√≥n entre ancho y largo del p√©talo
sns.scatterplot(x=iris['PetalWidthCm'],
                y=iris['PetalLengthCm'],
                hue=iris['Species'],
                palette="viridis",
                ax=ax[0])

# Mejoras del primer gr√°fico
ax[0].set_title("Relaci√≥n entre el ancho y largo del p√©talo", fontsize=14)
ax[0].set_xlabel("Ancho del p√©talo (PetalWidthCm)", fontsize=12)
ax[0].set_ylabel("Largo del p√©talo (PetalLengthCm)", fontsize=12)
ax[0].legend(title="Especie", loc="upper left")

# Segundo gr√°fico: Relaci√≥n entre ancho y largo del s√©palo
sns.scatterplot(x=iris['SepalWidthCm'],
                y=iris['SepalLengthCm'],
                hue=iris['Species'],
                palette="viridis",
                ax=ax[1])

# Mejoras del segundo gr√°fico
ax[1].set_title("Relaci√≥n entre el ancho y largo del s√©palo", fontsize=14)
ax[1].set_xlabel("Ancho del s√©palo (SepalWidthCm)", fontsize=12)
ax[1].set_ylabel("Largo del s√©palo (SepalLengthCm)", fontsize=12)
ax[1].legend(title="Especie", loc="upper left")

# Ajustar el espacio entre gr√°ficos
plt.tight_layout()

# Mostrar el gr√°fico
plt.show(
```



![image](https://github.com/user-attachments/assets/440c5b82-5af9-4094-a49a-a6c7fd260278)


![image](https://github.com/user-attachments/assets/2cccebc2-3a40-4b71-962a-6efca3d6c4b7)


Mirando los graficos, podemos sacar conclusiones:


 ¬øLas especies tienen agrupaciones bien definidas o est√°n mezcladas?

 Esto puede sugerir c√≥mo de diferenciadas son las especies en funci√≥n de estas caracter√≠sticas.

 Si ves que los puntos de una especie est√°n m√°s juntos o forman una l√≠nea o una forma espec√≠fica, podr√≠a indicar que esas especies tienen una relaci√≥n m√°s fuerte entre el largo y el ancho del p√©talo.


 Si las especies est√°n claramente separadas, podr√≠as concluir que el largo y el ancho del p√©talo son caracter√≠sticas muy √∫tiles para distinguirlas. Si las especies est√°n mezcladas, entonces esta relaci√≥n no es tan diferenciadora. ( verifica si las especies est√°n bien separadas o si hay superposici√≥n.)


Si alguna de las especies tiene un solapamiento significativo en las mediciones del s√©palo, esto podr√≠a sugerir que el s√©palo no es tan √∫til para distinguir esas especies en particular.

¬øHay alguna especie que tenga una tendencia m√°s clara en la forma de dispersi√≥n (por ejemplo, si una especie tiene s√©palos m√°s grandes o m√°s peque√±os en comparaci√≥n con las otras)?




 Si ambos gr√°ficos muestran que las especies est√°n claramente diferenciadas por las dimensiones del p√©talo y el s√©palo (tanto en ancho como en largo), entonces esas caracter√≠sticas son √∫tiles para la clasificaci√≥n. Puedes decir que el largo y el ancho del p√©talo son particularmente buenos para diferenciar las especies.

 Si observas que alguna especie tiene mucho solapamiento con otras, podr√≠a indicar que esas especies no son tan f√°cilmente diferenciables solo con esas dos caracter√≠sticas, y quiz√°s debas considerar otras medidas (como el ancho y largo de los p√©talos y s√©palos en combinaci√≥n con otras caracter√≠sticas).

 Si los gr√°ficos muestran una relaci√≥n fuerte entre las dimensiones del p√©talo o del s√©palo (por ejemplo, largo y ancho del p√©talo var√≠an en conjunto), esto podr√≠a indicar que hay una correlaci√≥n en esas dimensiones que puede ser aprovechada en modelos predictivos o an√°lisis futuros.

**En resumen**, la clave est√° en observar c√≥mo se agrupan o separan las especies en estos dos gr√°ficos. Si las especies se separan bien, puedes confirmar que las caracter√≠sticas del p√©talo y el s√©palo son √∫tiles para diferenciar las especies.


```py
# Graficos de Densidad: se usa para visualizar la distribuci√≥n de una variable num√©rica

sns.FacetGrid(iris, hue="Species", height=6).map(sns.kdeplot, "PetalLengthCm").add_legend()

sns.FacetGrid(iris, hue="Species", height=6).map(sns.kdeplot, "PetalWidthCm").add_legend()

sns.FacetGrid(iris, hue="Species", height=6).map(sns.kdeplot, "SepalLengthCm").add_legend()

sns.FacetGrid(iris, hue="Species", height=6).map(sns.kdeplot, "SepalWidthCm").add_legend()
```

![image](https://github.com/user-attachments/assets/01fa109f-f14d-4eaf-ac9c-e3daf54567bf)



![image](https://github.com/user-attachments/assets/673da407-9c82-4ba8-8904-fcc74f553c29)



üí° Conclusi√≥n 1 : sugiere que la longitud del p√©talo(PetalLengthCm) es una variable clave para la clasificaci√≥n/diferenciar de especies.

                  Setosa tiene p√©talos m√°s cortos y concentrados en un rango peque√±o.

                  Versicolor y Virginica tienen p√©talos m√°s largos, pero con cierta superposici√≥n


üí° Conclusi√≥n 2:  Sin embargo, hay menos solapamiento que en PetalLengthCm, lo que sugiere que el ancho del p√©talo (PetalWidthCm) tambi√©n es un buen diferenciador de especies.

                  Setosa tiene valores mucho m√°s bajos, mientras que Versicolor y Virginica se superponen en algunos puntos.

### 6 - Modelos de Machine Learning.

este es un ejercicio de clasificaci√≥n, por lo que todos los algoritmos a implementar deber√°n ser para este tipo de problemas

Comencemos a construir nuestros modelos con todos los datos, lo primero que debemos hacer es separar los datos con las caracter√≠sticas, que vendr√≠an siendo todas las columnas (los vamos a llamar ‚ÄúX‚Äù), menos la columna de especies (la que llamamos variable ‚Äúy‚Äù).

```py
# Separar las variables independientes y dependientes


       
# se elimina la columna 'Species' del DataFrame iris, o sea, se crea un nuevo DataFrame sin la columna Species y se asigna a la variable X.
# Ahora, X contiene solo las variables independientes.
X = iris.drop(columns=['Species']) 
                       
# Extrae la columna Species del DataFrame iris y la asigna a la variable "y".
# Ahora, y contiene los valores de la variable dependiente, es decir, las especies de las flores.
y = iris['Species']
```


¬øPor qu√© es necesario?

La separaci√≥n entre variables independientes (X) y la variable dependiente (y) es un paso est√°ndar en Machine Learning. La mayor√≠a de los modelos requieren esta separaci√≥n porque:

X (caracter√≠sticas) es lo que el modelo usa para aprender patrones. y (objetivo) es lo que el modelo intenta predecir.

Sin esta separaci√≥n, no podr√≠as entrenar un modelo correctamente,ya que no sabr√° qu√© datos usar como entrada (X) ni qu√© valores predecir (y).


Ahora, para entrenar nuestro modelo de Machine Learning y poder saber si esta funcionando correctamente, dividimos nuestro dataset de datos en conjuntos de entrenamiento y prueba.


```py
# X: Las variables independientes (caracter√≠sticas
# y: La variable dependiente (objetivo).
# test_size=0.2 --> Proporci√≥n del conjunto de prueba : 20% de los datos para prueba y el 80% restante para entrenamiento.
# random_state=42 :  Controla la aleatoriedad en la divisi√≥n de datos.

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print('Son {} datos para entrenamiento y {} datos para prueba'.format(X_train.shape[0], X_test.shape[0]))
```

Salida:

![image](https://github.com/user-attachments/assets/801e2b00-0fcf-48a8-acb8-e190d13ca94a)


El m√©todo train_test_split devuelve 4 conjuntos:

Conjunto de entrenamiento: Usado para entrenar el modelo.

        Variables independientes: X_train

        Variable dependiente: y_train

Conjunto de prueba: Usado para evaluar el modelo una vez entrenado.

        Variables independientes: X_test

        Variable dependiente: y_test





¬øPor qu√© es necesario dividir los datos?

La divisi√≥n en conjuntos de entrenamiento y prueba es crucial para construir un modelo de Machine Learning confiable:

Entrenamiento (X_train, y_train): El modelo aprende patrones en los datos. 

Prueba (X_test, y_test): Permite evaluar el rendimiento del modelo en datos no vistos (que simulan nuevos datos en el mundo real).

¬øQu√© pasa si no lo haces?

 Si no divides los datos y usas todo para entrenar:

El modelo puede memorizar los datos en lugar de generalizar patrones. Esto se llama sobreajuste (overfitting). No podr√≠as evaluar si el modelo funcionar√° bien con nuevos datos.



Prop√≥sito: Verificar qu√© tan bien el modelo aprendi√≥ los datos que se le proporcionaron durante el entrenamiento.

Aqu√≠ el modelo tiene ventaja porque ya vio estos datos y puede "memorizar" patrones espec√≠ficos.

Conjunto de Prueba (X_test, y_test):

Prop√≥sito: Medir qu√© tan bien el modelo generaliza a datos que nunca ha visto antes. Es m√°s importante porque refleja el rendimiento del modelo en datos del mundo real

#### 6.1 - Ahora si empecemos a aplicar los algoritmos de Machine Learning

##### Como forma de aprendizaje , en primer lugar usaremos el modelo de Regresion Logistica

```py
# Creaci√≥n del modelo de Regresi√≥n Log√≠stica.
# El m√©todo .fit(X_train, y_train) se usa para entrenar el modelo.
modelo = LogisticRegression(max_iter=200)
modelo.fit(X_train, y_train)                                   
```
Ahora vamos a hacer predicciones con el modelo ya entrenado,donde tomamos los datos X_test (que nunca fueron vistos por el modelo durante el entrenamiento).
usa el modelo entrenado para predecir nuevas etiquetas.

```py
# Devuelve una lista y_pred con las clases predichas (las categor√≠as a las que el modelo cree que pertenecen los datos).
y_pred = modelo.predict(X_test)
```
Las predicciones y_pred pueden compararse con los valores reales y_test para evaluar el modelo.


```py
# Calcular las m√©tricas de desempe√±o
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro', zero_division=1)
recall = recall_score(y_test, y_pred, average='macro', zero_division=1)
f1 = f1_score(y_test, y_pred, average='macro', zero_division=1)

# Crear y mostrar la tabla con las m√©tricas
metrics = pd.DataFrame({
    "M√©trica": ["Exactitud", "Precisi√≥n", "Recall", "F1 Score"],
    "Valor": [accuracy, precision, recall, f1]
})

# Mostrar las m√©tricas en una tabla visual
fig, ax = plt.subplots(figsize=(5, 2))
ax.axis('tight')
ax.axis('off')
table_metrics = ax.table(cellText=metrics.values, colLabels=metrics.columns, loc='center')

plt.show()

# Calcular la matriz de confusi√≥n
conf_matrix = confusion_matrix(y_test, y_pred)

# Mostrar la matriz de confusi√≥n con un mapa de calor
plt.figure(figsize=(5, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=set(y_test), yticklabels=set(y_test))

# Resaltar los labels de los ejes
plt.xlabel("Predicci√≥n", fontsize=12, fontweight="bold", color="blue")  # Verde
plt.ylabel("Real", fontsize=12, fontweight="bold", color="green")  # Amarillo

plt.title("Matriz de Confusi√≥n")
plt.show()

```
![image](https://github.com/user-attachments/assets/c78d6224-7c5b-42d1-bfd7-aa5d8221205f)




el modelo predijo correctamente todas las muestras en el conjunto de prueba, o sea, el modelo es capaz de generalizar correctamente.
```py
NOTA:El dataset Iris es un conjunto de datos cl√°sico, bien balanceado y peque√±o, con solo 150 muestras (50 muestras por cada una de las 3 especies).

Sin embargo, ser√≠a recomendable validar el modelo con otros conjuntos de datos o realizar una validaci√≥n cruzada para asegurarte de que el modelo no est√© sobreajustado a los datos.

```
### Ahora,a modo de ejemplo, cambiamos los valarores de los datos para entrenamiento y prueba: test_size=0.6  (60 datos para entrenamiento y 90 datos para prueba) y observamos que pasa.
```py
# Son 60 datos para entrenamiento y 90 datos para prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=42)
```
![image](https://github.com/user-attachments/assets/06aaf587-7b58-4cd0-bbfc-22e1eb7dac4d)


![image](https://github.com/user-attachments/assets/cf791fb5-d1ef-47b5-8258-ac282a11dd79)



